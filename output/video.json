{
    "url": "https://www.youtube.com/watch?v=kuDuJWvho7Q",
    "title": "Introduction to Bright Data | Scraping Browser",
    "channel": {
        "url": "https://www.youtube.com/@BrightData",
        "name": "Bright Data",
        "image": "https://yt3.ggpht.com/wyXxH3Xz746Nol22MAIgRqgvWEypemQoPmyEvxTEXaQPbAGZAM-MHwGl1p9FkDAYb7UT2sYNOw=s48-c-k-c0x00ffffff-no-rj",
        "subs": "구독자 6.04천명"
    },
    "views": "조회수 18,732회",
    "publication_date": "2023. 6. 14.",
    "description": "Welcome to our comprehensive guide on setting up and using Bright Data's Scraping Browser for efficient web data extraction. This video walks you through the process of setting up the Scraping Browser, highlighting its unique features and benefits.\nIntroduction to Bright Data's Scraping Browser\nNavigating the 'Proxies and Scraping Infrastructure' page\nCreating and Naming Your Scraping Browser\nExplaining User Interaction, Geo-Restrictions, and IP Rate Limits\nBreakdown of Costs for Using the Scraping Browser\nAccess Parameters and Their Importance\nIntegration Examples: Puppeteer in Node.js and Playwright in Python\nIntroduction to Web Scraping 'Today's Deals' from Amazon.com\nAutomated Data Extraction Process\nStatistics of Data Usage\nBenefits of Automated Web Scraping\nWhether you're looking to extract data behind user interactions, dealing with geo-restrictions, or IP rate limits, Bright Data's Scraping Browser provides comprehensive solutions for your needs. In this video, we also delve into a practical demonstration using Puppeteer and Python, illustrating how this browser can help you access and extract data efficiently.\n\nTo learn more about Bright Data's Scraping Browser: https://brightdata.com/products/scrap...\n\n#BrightData #ScrapingBrowser #WebScraping #Puppeteer #Python #Nodejs #Playwright #DataExtraction\n\n\n\n\n\n\nRegen",
    "likes": 94,
    "transcript": "- Let's take a look at Bright Data's Scraping Browser\nto see how we can use a dedicated web browser\nto get all the data we need from a website,\neven when there's no API.\nWhen you navigate into the Proxies\nand Scraping Infrastructure page\nthat we greeted with various different proxies,\nthe one we wanna look at today is the Scraping Browser.\nTo create one, we're gonna go ahead and click Get Started,\nand all we have to do is give our scraping browser a name,\nand for this one we'll call it Scrapy.\nAnd this is gonna be really useful for any site\nthat has data that might be behind some user interaction\nor that might be geo-restricted or IP-rate-limited\nsince we'll be using Bright Data's proxy network.\nAnd over here on the side,\nyou can see a breakdown of the estimated cost\nof using the Scraping Browser.\nNow that we've created the name, that's essentially it.\nWe'll go ahead and click Add.\nWe are immediately taken to the Access parameters page,\nthat gives us our host, username, and password.\nMake sure to keep this secret.\nIf you want examples on how to integrate it,\nyou can click over here to get some integration examples.\nYou'll wanna use puppeteer in Node.js\nor Playwright in Python.\nNow I'm gonna go ahead and use puppeteer-core\nand show you guys an example of how to use it.\nNow to fully utilize this,\nyou will have to have some type of knowledge\nwith programming.\nNow, it's not overly complicated.\nI'm using Node.js with puppeteer.\nYou can find the respective documentation\non each of their websites.\nNow what I've created here is a simple Node.js application,\nwhich is going to navigate to amazon.com.\nIt's gonna search for the Today Deals link\nand click that once it finds it.\nIt's gonna wait for something to load on the next page,\nthen it's going to parse all the deals on there\nand return us the deal and the name of the product.\nNow, if I were an actual user doing this,\nit would be navigating to the Amazon homepage,\nclicking on Today's Deals,\nand browsing through all of these deals manually,\nbut our app is going to do this automatically.\nSo when running this app,\nyou can see it's spitting out all of the findings\nto the console.\nYou're free to do whatever you want with this information,\nbut for this example,\nwe're just getting a large list of everything\nthat Amazon has for Today's Deals.\nGoing back to our scraping browser, under Statistics,\nyou can see that we've only used 11.7 megabytes,\nwhich essentially cost us pennies.\nSo this is an extremely efficient way\nto get any data you want from any website,\nno matter if it requires user interaction\nor if there's no API.\n",
    "reply_count": 12
}